{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from new mapping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from mirnylib import h5dict, genome, plotting\n",
    "from hiclib import mapping, fragmentHiC, highResBinnedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_db = genome.Genome('/home/shared_data/Annotation/UCSC/Mouse_Genome/MM9/Mus_musculus/UCSC/mm9/Sequence/WholeGenomeFasta/genome.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/xli/Data/Haihui/CD8-HP/HiC_2019/Data/Naive'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/Downloads/mirnylab/mirnylib/h5dict.py:103: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  data = pickle.loads(self._h5file[self.self_key].value)\n",
      "/home/xli/Downloads/mirnylab/mirnylib/h5dict.py:134: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  value = self._h5file[key].value\n"
     ]
    }
   ],
   "source": [
    "fname_list = ['19092FL-06-01_S1_L00%d_mapped_reads.hdf5' % i for i in range(1,3)]\n",
    "#fname_list = ['WT_CD8_p%d_mapped_reads.hdf5' % i for i in range(1,7)]\n",
    "mapped_reads_list = []\n",
    "for fname in fname_list:\n",
    "    mapped_reads_list.append(h5dict.h5dict(fname))\n",
    "\n",
    "combine_mapped_reads = h5dict.h5dict('WT_CD8_1910_mapped_reads.hdf5')\n",
    "\n",
    "combine_mapped_reads['chrms1'] = np.hstack(map(lambda k: k['chrms1'], mapped_reads_list))\n",
    "combine_mapped_reads['chrms2'] = np.hstack(map(lambda k: k['chrms2'], mapped_reads_list))\n",
    "combine_mapped_reads['cuts1'] = np.hstack(map(lambda k: k['cuts1'], mapped_reads_list))\n",
    "combine_mapped_reads['cuts2'] = np.hstack(map(lambda k: k['cuts2'], mapped_reads_list))\n",
    "combine_mapped_reads['misc'] = map(lambda k: k['misc'], mapped_reads_list)[0]\n",
    "combine_mapped_reads['strands1'] = np.hstack(map(lambda k: k['strands1'], mapped_reads_list))\n",
    "combine_mapped_reads['strands2'] = np.hstack(map(lambda k: k['strands1'], mapped_reads_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> New dataset opened, genome WholeGenomeFasta, filename = WT_CD8_1910_fragment_dataset.hdf5\n",
      "     loading data from file WT_CD8_1910_mapped_reads.hdf5 (assuming h5dict)\n",
      "raw read count file {0} does not exist\n",
      "Count not find raw read count\n",
      "filtering SS reads\n",
      "Keeping same-fragment reads\n",
      "keeping --> <-- reads even if they exceed maximumMoleculeLength\n",
      "300_validPairs:  561051531\n"
     ]
    }
   ],
   "source": [
    "### from mapped reads to get fragment\n",
    "fragments = fragmentHiC.HiCdataset(\n",
    "    filename='WT_CD8_1910_fragment_dataset.hdf5',\n",
    "    enzymeName='HindIII',\n",
    "    genome=genome_db,\n",
    "    mode='w')\n",
    "\n",
    "fragments.parseInputData(\n",
    "    dictLike='WT_CD8_1910_mapped_reads.hdf5', keepSingleSided=False, keepSameFragment=True, keepReadsMolecules=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Filtering duplicates in DS reads: \n",
      "Sorting using 2 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda2/lib/python2.7/site-packages/hiclib/fragmentHiC.py:600: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if outVariable[1] == \"ToDefine\":\n",
      "/opt/miniconda2/lib/python2.7/site-packages/hiclib/fragmentHiC.py:600: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if outVariable[1] == \"ToDefine\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> By chromosome Heatmap saved to 'WT_CD8_1910_heatmap-res-100K.hdf5' at 100000 resolution\n"
     ]
    }
   ],
   "source": [
    "fragments.filterDuplicates(mode='ram')\n",
    "fragments._sortData()\n",
    "\n",
    "#fragments = fragmentHiC.HiCdataset('WT_CD8_1910_fragment_dataset.hdf5', genome_db, enzymeName='HindIII')\n",
    "\n",
    "#fragments.filterDuplicates(mode='ram')\n",
    "\n",
    "fragments.saveByChromosomeHeatmap('WT_CD8_1910_heatmap-res-100K.hdf5', resolution=100000)\n",
    "\n",
    "#fragments.printMetadata(saveTo=\"DKO_CD8_2016_statistics.txt\")\n",
    "\n",
    "#print \"# of Fragments after duplciate removal: \" + str(fragments.fragmentSum(strands=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments.printMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### data for generating .hiC\n",
    "#fragments = fragmentHiC.HiCdataset('DKO_CD8_fragment_dataset.hdf5', genome_db, enzymeName='HindIII')\n",
    "outdir = '/home/xli/Data_Processing/Haihui/CD8-HP/HiC_2019/Data/201910/iterative_mapping_bam/Naive/DKO_CD8_1910/'\n",
    "chrms1_array = np.empty_like(fragments.h5dict['chrms1'], dtype='|S5')\n",
    "for index, chrmLabel in fragments.genome.idx2label.iteritems():\n",
    "    chrms1_array[np.where(fragments.h5dict['chrms1'] == index)] = chrmLabel\n",
    "\n",
    "chrms2_array = np.empty_like(fragments.h5dict['chrms2'], dtype='|S5')\n",
    "for index, chrmLabel in fragments.genome.idx2label.iteritems():\n",
    "    chrms2_array[np.where(fragments.h5dict['chrms2'] == index)] = chrmLabel\n",
    "\n",
    "k = 10\n",
    "index_list = np.linspace(0, fragments.N, k + 1, dtype=int)\n",
    "\n",
    "for i in range(1,k+1):\n",
    "    print i; sys.stdout.flush()\n",
    "    start, end = index_list[i-1], index_list[i]\n",
    "    df = pd.DataFrame({'str1': 1 - fragments.h5dict['strands1'][start : end],\n",
    "                       'chr1': chrms1_array[start : end],\n",
    "                       'pos1': fragments.h5dict['cuts1'][start : end],\n",
    "                       'frag1': 0,\n",
    "                       'str2': 1 - fragments.h5dict['strands2'][start : end],\n",
    "                       'chr2': chrms2_array[start : end],\n",
    "                       'pos2': fragments.h5dict['cuts2'][start : end],\n",
    "                       'frag2': 1\n",
    "                      },\n",
    "                      columns=['str1','chr1','pos1','frag1','str2','chr2','pos2','frag2'])\n",
    "\n",
    "    df.to_csv(outdir+'DKO_CD8_1910_Juicebox_input.txt', sep='\\t', index=None, header=None, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_CD8_BD = highResBinnedData.HiResHiC(genome_db, 100000, 'WT_CD8_1910_heatmap-res-100K.hdf5', mode='r+')\n",
    "WT_CD8_BD.loadData('WT_CD8_1910_heatmap-res-100K.hdf5')\n",
    "outdir = '/home/xli/Data/Haihui/CD8-HP/HiC_2019/Data/Naive_Merge_2016_1910/mapped_reads/matrix_res_100k/1910/WT_CD8/'\n",
    "pd.DataFrame({'chrmLabels': WT_CD8_BD.genome.chrmLabels, 'chrmLens': WT_CD8_BD.genome.chrmLens}).to_csv(outdir + 'mm9_genome_size.txt', index=None, header=None, sep='\\t')\n",
    "pd.DataFrame({'chrmLabels': WT_CD8_BD.genome.chrmLabels, 'filename': map(lambda chrm: outdir + 'WT_CD8_' + chrm + '.matrix', WT_CD8_BD.genome.chrmLabels)}).to_csv(outdir + 'WT_CD8_intrachrom_matrix_list.txt', index=None, header=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass = 0, Error = 2.364650\n",
      "Pass = 1, Error = 0.980156\n",
      "Pass = 2, Error = 0.862228\n",
      "Pass = 3, Error = 0.660686\n",
      "Pass = 4, Error = 0.498827\n",
      "Pass = 5, Error = 0.399465\n",
      "Pass = 6, Error = 0.336104\n",
      "Pass = 7, Error = 0.290996\n",
      "Pass = 8, Error = 0.257162\n",
      "Pass = 9, Error = 0.229817\n",
      "Pass = 10, Error = 0.207530\n",
      "Pass = 11, Error = 0.189336\n",
      "Pass = 12, Error = 0.173901\n",
      "Pass = 13, Error = 0.160792\n",
      "Pass = 14, Error = 0.149397\n",
      "Pass = 15, Error = 0.139430\n",
      "Pass = 16, Error = 0.130689\n",
      "Pass = 17, Error = 0.123026\n",
      "Pass = 18, Error = 0.116149\n",
      "Pass = 19, Error = 0.109991\n",
      "Pass = 20, Error = 0.104490\n",
      "Pass = 21, Error = 0.099481\n",
      "Pass = 22, Error = 0.094913\n",
      "Pass = 23, Error = 0.090750\n",
      "Pass = 24, Error = 0.086923\n",
      "Pass = 25, Error = 0.083409\n",
      "Pass = 26, Error = 0.080165\n",
      "Pass = 27, Error = 0.077148\n",
      "Pass = 28, Error = 0.074347\n",
      "Pass = 29, Error = 0.071743\n",
      "Pass = 30, Error = 0.069317\n",
      "Pass = 31, Error = 0.067042\n",
      "Pass = 32, Error = 0.064911\n",
      "Pass = 33, Error = 0.062909\n",
      "Pass = 34, Error = 0.061022\n",
      "Pass = 35, Error = 0.059247\n",
      "Pass = 36, Error = 0.057573\n",
      "Pass = 37, Error = 0.055990\n",
      "Pass = 38, Error = 0.054497\n",
      "Pass = 39, Error = 0.053083\n",
      "Pass = 40, Error = 0.051732\n",
      "Pass = 41, Error = 0.050449\n",
      "Pass = 42, Error = 0.049224\n",
      "Pass = 43, Error = 0.048057\n",
      "Pass = 44, Error = 0.046944\n",
      "Pass = 45, Error = 0.045882\n",
      "Pass = 46, Error = 0.044866\n",
      "Pass = 47, Error = 0.043894\n",
      "Pass = 48, Error = 0.042965\n",
      "Pass = 49, Error = 0.042074\n",
      "Pass = 50, Error = 0.041222\n",
      "Pass = 51, Error = 0.040399\n",
      "Pass = 52, Error = 0.039610\n",
      "Pass = 53, Error = 0.038851\n",
      "Pass = 54, Error = 0.038121\n",
      "Pass = 55, Error = 0.037416\n",
      "Pass = 56, Error = 0.036736\n",
      "Pass = 57, Error = 0.036081\n",
      "Pass = 58, Error = 0.035448\n",
      "Pass = 59, Error = 0.034837\n",
      "Pass = 60, Error = 0.034251\n",
      "Pass = 61, Error = 0.033680\n",
      "Pass = 62, Error = 0.033128\n",
      "Pass = 63, Error = 0.032594\n",
      "Pass = 64, Error = 0.032077\n",
      "Pass = 65, Error = 0.031575\n",
      "Pass = 66, Error = 0.031089\n",
      "Pass = 67, Error = 0.030617\n",
      "Pass = 68, Error = 0.030159\n",
      "Pass = 69, Error = 0.029715\n",
      "Pass = 70, Error = 0.029284\n",
      "Pass = 71, Error = 0.028865\n",
      "Pass = 72, Error = 0.028458\n",
      "Pass = 73, Error = 0.028061\n",
      "Pass = 74, Error = 0.027676\n",
      "Pass = 75, Error = 0.027301\n",
      "Pass = 76, Error = 0.026936\n",
      "Pass = 77, Error = 0.026581\n",
      "Pass = 78, Error = 0.026235\n",
      "Pass = 79, Error = 0.025898\n",
      "Pass = 80, Error = 0.025569\n",
      "Pass = 81, Error = 0.025249\n",
      "Pass = 82, Error = 0.024937\n",
      "Pass = 83, Error = 0.024632\n",
      "Pass = 84, Error = 0.024335\n",
      "Pass = 85, Error = 0.024044\n",
      "Pass = 86, Error = 0.023761\n",
      "Pass = 87, Error = 0.023484\n",
      "Pass = 88, Error = 0.023213\n",
      "Pass = 89, Error = 0.022949\n",
      "Pass = 90, Error = 0.022690\n",
      "Pass = 91, Error = 0.022437\n",
      "Pass = 93, Error = 0.021948\n",
      "Pass = 94, Error = 0.021712\n",
      "Pass = 95, Error = 0.021480\n",
      "Pass = 96, Error = 0.021253\n",
      "Pass = 97, Error = 0.021032\n",
      "Pass = 98, Error = 0.020814\n",
      "Pass = 99, Error = 0.020601\n",
      "Pass = 100, Error = 0.020393\n",
      "Pass = 101, Error = 0.020189\n",
      "Pass = 102, Error = 0.019988\n",
      "Pass = 103, Error = 0.019792\n",
      "Pass = 104, Error = 0.019599\n",
      "Pass = 105, Error = 0.019410\n",
      "Pass = 106, Error = 0.019224\n",
      "Pass = 107, Error = 0.019042\n",
      "Pass = 108, Error = 0.018864\n",
      "Pass = 109, Error = 0.018689\n",
      "Pass = 110, Error = 0.018517\n",
      "Pass = 111, Error = 0.018348\n",
      "Pass = 112, Error = 0.018182\n",
      "Pass = 113, Error = 0.018019\n",
      "Pass = 114, Error = 0.017859\n",
      "Pass = 115, Error = 0.017702\n",
      "Pass = 116, Error = 0.017548\n",
      "Pass = 117, Error = 0.017396\n",
      "Pass = 118, Error = 0.017247\n",
      "Pass = 119, Error = 0.017100\n",
      "Pass = 120, Error = 0.016956\n",
      "Pass = 121, Error = 0.016814\n",
      "Pass = 122, Error = 0.016675\n",
      "Pass = 123, Error = 0.016538\n",
      "Pass = 124, Error = 0.016403\n",
      "Pass = 125, Error = 0.016270\n",
      "Pass = 126, Error = 0.016140\n",
      "Pass = 127, Error = 0.016011\n",
      "Pass = 128, Error = 0.015884\n",
      "Pass = 129, Error = 0.015760\n",
      "Pass = 130, Error = 0.015637\n",
      "Pass = 131, Error = 0.015517\n",
      "Pass = 132, Error = 0.015398\n",
      "Pass = 133, Error = 0.015281\n",
      "Pass = 134, Error = 0.015166\n",
      "Pass = 135, Error = 0.015052\n",
      "Pass = 136, Error = 0.014940\n",
      "Pass = 137, Error = 0.014830\n",
      "Pass = 138, Error = 0.014722\n",
      "Pass = 139, Error = 0.014615\n",
      "Pass = 140, Error = 0.014509\n",
      "Pass = 141, Error = 0.014405\n",
      "Pass = 142, Error = 0.014303\n",
      "Pass = 143, Error = 0.014202\n",
      "Pass = 144, Error = 0.014102\n",
      "Pass = 145, Error = 0.014004\n",
      "Pass = 146, Error = 0.013907\n",
      "Pass = 147, Error = 0.013811\n",
      "Pass = 148, Error = 0.013717\n",
      "Pass = 149, Error = 0.013624\n",
      "Pass = 150, Error = 0.013532\n",
      "Pass = 151, Error = 0.013441\n",
      "Pass = 152, Error = 0.013352\n",
      "Pass = 153, Error = 0.013264\n",
      "Pass = 154, Error = 0.013177\n",
      "Pass = 155, Error = 0.013091\n",
      "Pass = 156, Error = 0.013006\n",
      "Pass = 157, Error = 0.012923\n",
      "Pass = 158, Error = 0.012840\n",
      "Pass = 159, Error = 0.012759\n",
      "Pass = 160, Error = 0.012678\n",
      "Pass = 161, Error = 0.012599\n",
      "Pass = 162, Error = 0.012520\n",
      "Pass = 163, Error = 0.012443\n",
      "Pass = 164, Error = 0.012366\n",
      "Pass = 165, Error = 0.012290\n",
      "Pass = 166, Error = 0.012216\n",
      "Pass = 167, Error = 0.012142\n",
      "Pass = 168, Error = 0.012069\n",
      "Pass = 169, Error = 0.011997\n",
      "Pass = 170, Error = 0.011925\n",
      "Pass = 171, Error = 0.011855\n",
      "Pass = 172, Error = 0.011786\n",
      "Pass = 173, Error = 0.011717\n",
      "Pass = 174, Error = 0.011649\n",
      "Pass = 175, Error = 0.011582\n",
      "Pass = 176, Error = 0.011515\n",
      "Pass = 177, Error = 0.011450\n",
      "Pass = 178, Error = 0.011385\n",
      "Pass = 179, Error = 0.011321\n",
      "Pass = 180, Error = 0.011257\n",
      "Pass = 181, Error = 0.011195\n",
      "Pass = 182, Error = 0.011132\n",
      "Pass = 183, Error = 0.011071\n",
      "Pass = 184, Error = 0.011010\n",
      "Pass = 185, Error = 0.010950\n",
      "Pass = 186, Error = 0.010891\n",
      "Pass = 187, Error = 0.010832\n",
      "Pass = 188, Error = 0.010774\n",
      "Pass = 189, Error = 0.010716\n",
      "Pass = 190, Error = 0.010660\n",
      "Pass = 191, Error = 0.010603\n",
      "Pass = 192, Error = 0.010547\n",
      "Pass = 193, Error = 0.010492\n",
      "Pass = 194, Error = 0.010438\n",
      "Pass = 195, Error = 0.010384\n",
      "Pass = 196, Error = 0.010330\n",
      "Pass = 197, Error = 0.010277\n",
      "Pass = 198, Error = 0.010225\n",
      "Pass = 199, Error = 0.010173\n",
      "Pass = 200, Error = 0.010122\n",
      "Pass = 201, Error = 0.010071\n",
      "Pass = 202, Error = 0.010021\n",
      "Pass = 203, Error = 0.009971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT_CD8_BD.removeDiagonal()\n",
    "WT_CD8_BD.iterativeCorrection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AttributeError: \"'h5dict' object has no attribute '_h5file'\" in <bound method h5dict.__del__ of <mirnylib.h5dict.h5dict object at 0x7f44df4823d0>> ignored\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HiResHiC' object has no attribute 'saveCooler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7e5f945b80bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWT_CD8_BD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveCooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DKO_CD8_1910-res-10K.cool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'HiResHiC' object has no attribute 'saveCooler'"
     ]
    }
   ],
   "source": [
    "WT_CD8_BD.saveCooler('DKO_CD8_1910-res-10K.cool', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n",
      "(4, 4)\n",
      "(5, 5)\n",
      "(6, 6)\n",
      "(7, 7)\n",
      "(8, 8)\n",
      "(9, 9)\n",
      "(10, 10)\n",
      "(11, 11)\n",
      "(12, 12)\n",
      "(13, 13)\n",
      "(14, 14)\n",
      "(15, 15)\n",
      "(16, 16)\n",
      "(17, 17)\n",
      "(18, 18)\n",
      "(19, 19)\n",
      "(20, 20)\n",
      "(21, 21)\n"
     ]
    }
   ],
   "source": [
    "for index, chrmLabel in WT_CD8_BD.genome.idx2label.iteritems():\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    print key\n",
    "    outputfile = 'WT_CD8_1910_' +  chrmLabel + '.matrix'\n",
    "    \n",
    "    \n",
    "    np.savetxt(outdir + outputfile, WT_CD8_BD._h5dict[key], fmt='%.2e', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> New dataset opened, genome iterative_mapping, filename = Tcf1_KO_na_CD8_fragment_dataset.hdf5\n",
      "----->!!!File already exists! It will be deleted\n",
      "\n",
      "     loading data from file Tcf1_KO_na_CD8_mapped_reads.hdf5 (assuming h5dict)\n",
      "raw read count file {0} does not exist\n",
      "Count not find raw read count\n",
      "filtering SS reads\n",
      "Keeping same-fragment reads\n",
      "keeping --> <-- reads even if they exceed maximumMoleculeLength\n",
      "300_validPairs:  196511151\n"
     ]
    }
   ],
   "source": [
    "fragments = fragmentHiC.HiCdataset(\n",
    "    filename='Tcf1_KO_na_CD8_fragment_dataset.hdf5',\n",
    "    enzymeName='HindIII',\n",
    "    genome=genome_db,\n",
    "    mode='w')\n",
    "\n",
    "fragments.parseInputData(\n",
    "    dictLike='Tcf1_KO_na_CD8_mapped_reads.hdf5', keepSingleSided=False, keepSameFragment=True, keepReadsMolecules=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131018607"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragments.fragmentSum(strands=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Filtering duplicates in DS reads: \n",
      "Sorted using default sort 300000000 131018607\n",
      "----> New dataset opened, genome iterative_mapping, filename = Tcf1_KO_na_CD8_fragment_dataset.hdf5\n",
      "----->!!!File already exists! It will be opened in the append mode\n",
      "\n",
      "----> By chromosome Heatmap saved to 'Tcf1_KO_na_CD8_heatmap-res-10K.hdf5' at 10000 resolution\n"
     ]
    }
   ],
   "source": [
    "fragments.filterDuplicates(mode='ram')\n",
    "fragments._sortData()\n",
    "\n",
    "fragments = fragmentHiC.HiCdataset('Tcf1_KO_na_CD8_fragment_dataset.hdf5', genome_db, enzymeName='HindIII')\n",
    "\n",
    "fragments.saveByChromosomeHeatmap('Tcf1_KO_na_CD8_heatmap-res-10K.hdf5', resolution=10000)\n",
    "\n",
    "fragments.printMetadata(saveTo=\"Tcf1_KO_na_CD8_statistics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TKO_CD8_BD = highResBinnedData.HiResHiC(genome_db, 10000, 'Tcf1_KO_na_CD8_heatmap-res-10K.hdf5', mode='r+')\n",
    "TKO_CD8_BD.loadData('Tcf1_KO_na_CD8_heatmap-res-10K.hdf5')\n",
    "outdir = '/home/lxiang/cloud_research/PengGroup/XLi/Data/Haihui/CD8-HP/HiC/1905/iterative_mapping/Tcf1_KO_na_CD8'\n",
    "pd.DataFrame({'chrmLabels': TKO_CD8_BD.genome.chrmLabels, 'chrmLens': TKO_CD8_BD.genome.chrmLens}).to_csv(outdir + '_mm9_genome_size.txt', index=None, header=None, sep='\\t')\n",
    "pd.DataFrame({'chrmLabels': TKO_CD8_BD.genome.chrmLabels, 'filename': map(lambda chrm: outdir + 'TKO_CD8_' + chrm + '.matrix', TKO_CD8_BD.genome.chrmLabels)}).to_csv(outdir + 'TKO_CD8_intrachrom_matrix_list.txt', index=None, header=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TKO_CD8_BD = highResBinnedData.HiResHiC(genome_db, 10000, 'Tcf1_KO_na_CD8_heatmap-res-10K-IC.hdf5')\n",
    "TKO_CD8_BD.loadData('Tcf1_KO_na_CD8_heatmap-res-10K.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass = 0, Error = 2.149347\n",
      "Pass = 1, Error = 0.966206\n",
      "Pass = 2, Error = 0.823797\n",
      "Pass = 3, Error = 0.622793\n",
      "Pass = 4, Error = 0.471504\n",
      "Pass = 5, Error = 0.379456\n",
      "Pass = 6, Error = 0.321074\n",
      "Pass = 7, Error = 0.279442\n",
      "Pass = 8, Error = 0.247432\n",
      "Pass = 9, Error = 0.221799\n",
      "Pass = 10, Error = 0.200904\n",
      "Pass = 11, Error = 0.183490\n",
      "Pass = 12, Error = 0.168734\n",
      "Pass = 13, Error = 0.156067\n",
      "Pass = 14, Error = 0.145185\n",
      "Pass = 15, Error = 0.135724\n",
      "Pass = 16, Error = 0.127386\n",
      "Pass = 17, Error = 0.119999\n",
      "Pass = 18, Error = 0.113419\n",
      "Pass = 19, Error = 0.107515\n",
      "Pass = 20, Error = 0.102192\n",
      "Pass = 21, Error = 0.097372\n",
      "Pass = 22, Error = 0.092959\n",
      "Pass = 23, Error = 0.088921\n",
      "Pass = 24, Error = 0.085220\n",
      "Pass = 25, Error = 0.081816\n",
      "Pass = 26, Error = 0.078670\n",
      "Pass = 27, Error = 0.075750\n",
      "Pass = 28, Error = 0.073037\n",
      "Pass = 29, Error = 0.070511\n",
      "Pass = 30, Error = 0.068153\n",
      "Pass = 31, Error = 0.065947\n",
      "Pass = 32, Error = 0.063876\n",
      "Pass = 33, Error = 0.061930\n",
      "Pass = 34, Error = 0.060099\n",
      "Pass = 35, Error = 0.058373\n",
      "Pass = 36, Error = 0.056743\n",
      "Pass = 37, Error = 0.055199\n",
      "Pass = 38, Error = 0.053736\n",
      "Pass = 39, Error = 0.052348\n",
      "Pass = 40, Error = 0.051029\n",
      "Pass = 41, Error = 0.049776\n",
      "Pass = 42, Error = 0.048582\n",
      "Pass = 43, Error = 0.047444\n",
      "Pass = 44, Error = 0.046358\n",
      "Pass = 45, Error = 0.045320\n",
      "Pass = 46, Error = 0.044328\n",
      "Pass = 47, Error = 0.043377\n",
      "Pass = 48, Error = 0.042467\n",
      "Pass = 49, Error = 0.041594\n",
      "Pass = 50, Error = 0.040756\n",
      "Pass = 51, Error = 0.039950\n",
      "Pass = 52, Error = 0.039175\n",
      "Pass = 53, Error = 0.038429\n",
      "Pass = 54, Error = 0.037711\n",
      "Pass = 55, Error = 0.037020\n",
      "Pass = 56, Error = 0.036353\n",
      "Pass = 57, Error = 0.035709\n",
      "Pass = 58, Error = 0.035089\n",
      "Pass = 59, Error = 0.034489\n"
     ]
    }
   ],
   "source": [
    "#TKO_CD8_BD.removeDiagonal()\n",
    "TKO_CD8_BD.iterativeCorrection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genome Size File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/home/lxiang/cloud_research/PengGroup/XLi/Data/Haihui/CD8-HP/HiC/1905/iterative_mapping/WT_na_CD8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'chrmLabels': WT_CD8_BD.genome.chrmLabels, 'chrmLens': WT_CD8_BD.genome.chrmLens}).to_csv(outdir + 'mm9_genome_size.txt', index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'chrmLabels': WT_CD8_BD.genome.chrmLabels, 'filename': map(lambda chrm: outdir + 'WT_CD8_' + chrm + '.matrix', WT_CD8_BD.genome.chrmLabels)}).to_csv(outdir + 'WT_CD8_intrachrom_matrix_list.txt', index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = fragmentHiC.HiCdataset('WT_CD8_fragment_dataset.hdf5', genome_db, enzymeName='HindIII')\n",
    "\n",
    "fragments.saveByChromosomeHeatmap('WT_CD8_heatmap-res-10K.hdf5', resolution=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_mapping_to_fragment_hdf(BAM_PATH, Cond_NAME):\n",
    "## Create a Class for storing\n",
    "    fragments = fragmentHiC.HiCdataset( filename=Cond_NAME+'_fragment_dataset.hdf5',\n",
    "        enzymeName='HindIII',genome=genome_db, mode='w')\n",
    "\n",
    "## Read from mapped_reads to hdf5\n",
    "    fragments.parseInputData(\n",
    "        dictLike= Cond_NAME+'_mapped_reads.hdf5', keepSingleSided=False, keepSameFragment=True, keepReadsMolecules=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> New dataset opened, genome iterative_mapping, filename = WT_CD8_fragment_dataset.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> New dataset opened, genome iterative_mapping, filename = WT_CD8_fragment_dataset.hdf5\n",
      "----> By chromosome Heatmap saved to 'WT_CD8_heatmap-res-10k.hdf5' at 10000 resolution\n"
     ]
    }
   ],
   "source": [
    "WT_CD8_fragments = fragmentHiC.HiCdataset(\n",
    "    filename='WT_CD8_fragment_dataset.hdf5',\n",
    "    enzymeName='HindIII',\n",
    "    genome=genome_db,\n",
    "    mode='r')\n",
    "#WT_CD8_fragments.fragmentSum(strands=1).sum()\n",
    "WT_CD8_fragments.saveByChromosomeHeatmap('WT_CD8_heatmap-res-10k.hdf5', resolution=10000)\n",
    "WT_CD8_BD = highResBinnedData.HiResHiC(genome_db, 10000, 'WT_CD8_read_count_heatmap-res-10K.hdf5', mode='a')\n",
    "WT_CD8_BD.loadData('WT_CD8_heatmap-res-10k.hdf5')\n",
    "\n",
    "for index, chrmLabel in WT_CD8_BD.genome.idx2label.iteritems():\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    outputfile = 'WT_CD8_1905_read_count_' +  chrmLabel + '.matrix'\n",
    "    np.savetxt(outdir + outputfile, WT_CD8_BD._h5dict[key], fmt='%i', delimiter='\\t') \n",
    "    \n",
    "# fmt='%.2e' for normalized matrix \n",
    "# fmt='%i' for raw read count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TKO_CD8_fragments = fragmentHiC.HiCdataset(\n",
    "    filename='Tcf1_KO_na_CD8_fragment_dataset.hdf5',\n",
    "    enzymeName='HindIII',\n",
    "    genome=genome_db,\n",
    "    mode='r')\n",
    "\n",
    "#WT_CD8_fragments.fragmentSum(strands=1).sum()\n",
    "TKO_CD8_fragments.saveByChromosomeHeatmap('TKO_CD8_heatmap-res-10k.hdf5', resolution=10000)\n",
    "TKO_CD8_BD = highResBinnedData.HiResHiC(genome_db, 10000, 'TKO_CD8_read_count_heatmap-res-10K.hdf5', mode='a')\n",
    "TKO_CD8_BD.loadData('TKO_CD8_heatmap-res-10k.hdf5')\n",
    "\n",
    "for index, chrmLabel in WT_CD8_BD.genome.idx2label.iteritems():\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    outputfile = 'TKO_CD8_1905_read_count_' +  chrmLabel + '.matrix'\n",
    "    np.savetxt(outdir + outputfile, TKO_CD8_BD._h5dict[key] , fmt='%i',  delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162305580.0\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for index, chrmLabel in WT_CD8_BD.genome.idx2label.iteritems():\n",
    "    #print index, chrmLabel\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    total += WT_CD8_BD._h5dict[key].sum()\n",
    "print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/lxiang/cloud_research/PengGroup/XLi/Data/Haihui/CD8-HP/HiC/1905/iterative_mapping'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12220.44415363108"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chrmLabel in WT_CD8_BD.genome.idx2label.iteritems():\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    outputfile = 'WT_CD8_1905_' +  chrmLabel + '.matrix'\n",
    "    np.savetxt(outdir + outputfile, WT_CD8_BD._h5dict[key], fmt='%.2e', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/home/lxiang/cloud_research/PengGroup/XLi/Data/Haihui/CD8-HP/HiC/1905/iterative_mapping/Tcf1_KO_na_CD8/'\n",
    "for index, chrmLabel in TKO_CD8_BD.genome.idx2label.iteritems():\n",
    "    key = '(%d, %d)' % (index, index)\n",
    "    outputfile = 'TKO_CD8_1905_' +  chrmLabel + '.matrix'\n",
    "    np.savetxt(outdir+outputfile, TKO_CD8_BD._h5dict[key], fmt='%.2e', delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
